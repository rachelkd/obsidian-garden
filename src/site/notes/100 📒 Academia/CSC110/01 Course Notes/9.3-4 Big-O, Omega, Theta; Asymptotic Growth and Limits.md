---
{"dg-publish":true,"dg-path":"academia/CSC110/01 Course Notes/9.3-4 Big-O, Omega, Theta; Asymptotic Growth and Limits.md","permalink":"/academia/csc-110/01-course-notes/9-3-4-big-o-omega-theta-asymptotic-growth-and-limits/","created":"2023-11-05T14:17:06.644-08:00","updated":"2023-11-06T12:54:30.208-08:00"}
---

#CSC110 

**Covered in:**
- [[100 ðŸ“’ Academia/CSC110/02 Lectures/Lecture 21 Asymptotic Notation for Function Growth\|Lecture 21 Asymptotic Notation for Function Growth]]
- [[100 ðŸ“’ Academia/CSC110/02 Lectures/Lecture 22 Properties of Asymptotic Notation and Basic Running-Time Analysis\|Lecture 22 Properties of Asymptotic Notation and Basic Running-Time Analysis]]

---

> [!note] 
> Check [[100 ðŸ“’ Academia/CSC110/02 Lectures/Lecture 21 Asymptotic Notation for Function Growth\|Lecture 21]] for notes on Omega and Theta

- Some functions are *bounded*
	- They never take on a value larger than some fixed constant
	- e.g., $f(n) = 1$, which always outputs the value 1, regardless of value $n$
- What does it mean to say that $g$ is Big-O of $f(n) = 1$
	- $$\begin{align*}
	  &g \in \mathcal{O}(f) \\
	  &\exists c, n_{0} \in \mathbb{R}^{+}, \forall n \in \mathbb{N} n \geq n_{0} \implies g(n) \leq c \cdot f(n) \\
	  &\exists c, n_{0} \in \mathbb{R}^{+}, \forall n \geq n_{0} \implies g(n) \leq c && ( \text{since } f(n) = 1)
	  \end{align*}$$
	- We say that such functions $g$ are **asymptotically bounded** with respect to their input
		- We write $g \in \mathcal{O}(1)$.
- We use $g \in \Omega (1)$ to express that functions are greater than or equal to some constant $c$
	- e.g., $g(n) = \frac{1}{n+1}$ is $\mathcal{O}(1)$, but *not* $\Omega (1)$.
		- Any function $g$ where $\displaystyle \lim_{n\to\infty} g(n) = 0$ is not $\Omega (1)$.

# Properties of Big-O, Omega, and Theta

## Elementary Functions

**Theorem. (Elementary function growth hierarchy theorem.)**
For all $a, b, \in \mathbb{R}^{+}$, the following statements are true:
	1. If $a > 1$ and $b > 1$, then $\log_{a}{n} \in \Theta(\log_{b}{n})$
	2. If $a < b$, then $n^{a} \in \mathcal{O}(b^{n})$ and $n^{a} \notin \Omega ( b^{n} )$
	3. If $a < b$, then $a^{n} \in \mathcal{O}(b^{n})$ and $a^{n} \notin \Omega (b^{n})$
	4. If $a > 1$, then $1 \in \mathcal{O}(\log_{a}{n}) and 1 \notin \Omega (\log_{a}{n})$
	5. $\log_{a}{n} \in \mathcal{O}(n^{b})$ and $log_{a}{n} \notin \Omega (n^{b})$
	6. If $b > 1$, then $n^{a} \in \mathcal{O} (b^{n})$ and $n^{a} \notin \Omega (b^{n})$
{ #9d9a95}


**Progression of functions towards larger and larger rates of growth**

![progression_of_functions.png|center|400](/img/user/Files/01%20CSC110/progression_of_functions.png)

## Basic properties

> [!note]
> **Theorem.** For all $f : \mathbb{N} \rightarrow \mathbb{R}^{\geq 0}$, $f \in \Theta(f)$.
> - This also implies that $f \in \mathcal{O}(f)$ and $f \in \Omega (f)$

> [!note] 
> **Theorem.** For all $f, g : \mathbb{N} \rightarrow \mathbb{R}^{\geq 0}, g \in \mathcal{O}(f) \iff f \in \Omega (g)$.
> - $g \in \Theta (f) \iff f \in \Theta (g)$

> [!note] 
> **Theorem.** For all $f, g, h : \mathbb{N} \rightarrow \mathbb{R}^{\geq 0}$:
> - If $f \in \mathcal{O}(g)$ and $g \in \mathcal{O}(h)$, $f \in \mathcal{O}(h)$
> - If $f \in \Omega (g)$ and $g \in \Omega(h)$, then $f \in \Omega (h)$
> - If $f \in \Theta (g)$ and $g \in \Theta (h)$, then $f \in \Theta (h)$


## Operations on functions

*Definition.* Let $f, g : \mathbb{N} \rightarrow \mathbb{R}^{\geq 0}$. We can define the **sum of $f$ and $g$** as the function $f + G : \mathbb{N} \rightarrow \mathbb{R}^{\geq 0}$ such that
$$\forall n \in \mathbb{N}, (f + g)(n) = f(n) + g(n)$$
> [!note] 
> **Theorem.** For all $f, g , h : \mathbb{N} \rightarrow \mathbb{R}^{\geq 0}$, the following hold:
> 1. If $f \in \mathcal{O}(h)$ and $g \in \mathcal{O}(h)$, then $f + g \in \mathcal{O}(h)$
> 2. If $f \in \Omega (h)$, then $f + g \in \Omega (h)$
> 3. If $f \in \Theta (h)$ and $g \in \mathcal{O}(h)$, then $f + g \in \Theta (h)$

# Asymptotic Growth and Limits

Let $f : \mathbb{N} \rightarrow \mathbb{R}$ and $L \in \mathbb{R}$. We have the following definitions:
$$\begin{align}
\displaystyle \lim_{n\to\infty} f(n) &= L
: \forall \epsilon \in \mathbb{R}^{+}, \exists n_{0} \in \mathbb{N}, n \geq n_{0}
\implies \mid f(n) - L \mid < \epsilon \\
\lim_{n\to\infty} f(n) &= \infty
: \forall M \in \mathbb{R}^{+}, \exists n_{0} \in \mathbb{N}, \forall n \in \mathbb{N}, n \geq n_{0}
\implies f(n) > M
\end{align}$$
 > [!note]
 > **Theorem.** For all $f, g : \mathbb{N} \rightarrow \mathbb{R}^{\geq 0}$, if $g(n) \neq 0$ for all $n \in \mathbb{N}$, then the following statements hold:
> 	1. If there exists $L \in \mathbb{R}^{+}$ such that $\displaystyle \lim_{n\to\infty} \frac{f(n)}{g(n)} = L$, then $g \in \Theta (f)$.
> 	2. If $\displaystyle \lim_{n\to\infty} \frac{f(n)}{g(n)} = 0$, then $f \in \mathcal{O}(g)$ and $f \notin \Theta (g)$.
> 	3. If $\displaystyle \lim_{n\to\infty} \frac{f(n)}{g(n)} = \infty$, then $f \in \Omega {g}$ and $f \notin \mathcal{O}(g)$.

