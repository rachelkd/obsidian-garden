---
{"dg-publish":true,"permalink":"/900-archive/uof-t/y1/csc-110/01-course-notes/9-analyzing-algorithm-running-time/9-7-analyzing-built-in-data-type-operations/","created":"2023-11-12T19:05:04.017-08:00","updated":"2023-12-14T13:27:11.004-08:00"}
---

#CSC110 

**Covered in:**
- [[900 Archive/UofT/Y1/CSC110/02 Lecture Notes/Lecture 24 Analyzing Built-In Data Type Operations\|Lecture 24 Analyzing Built-In Data Type Operations]]

---
```table-of-contents
```
---
# Timing operations

- Python module `timeit` tells us how long Python code takes to execute on our machine

```python
>>> from timeit import timeit
>>> timeit('5 + 15', number=1000)
1.9799976143985987e-05
```
- Call to `timeit` performs operation `5 + 15` (passed as string) one thousand times
- Function returns total time elapsed, in seconds, to perform all thousand operations
	- Value is specific to one machine

# How Python lists are stored in memory

- For every Python `list` object, the references to its elements are stored:
	- in a *contiguous* block of memory
- array-based list implementation
	- type of list implementation where the references to each list elements are always stored consecutively

## Fast list indexing

- Array-based list implemetation makes list indexing fast:
	- Accessing the $i$-th element can be done with simple arithmetic:
		- Take the memory address where the list starts
		- Increase it by $i$ blocks to obtain location of $i$-th element reference
		- **List indexing is a *constant-time* operation**
- **Assigning to a list index is a constant time operation**
	- `lst[1] = 100`

## Mutating contiguous memory

- Maintaining contiguity has implications for how insertion and deletion in a Python list
	- When a list element is deleted:
		- all items after it have to be moved back one memory block to fill the gap
	- When a list element is inserted:
		- all items after it have to be moved forward one block
	- e.g., Suppose we have a list `lst` of length $n$
		- We wish to remove the element at index $i$ in the list ($0 \leq i < n$)
		- $n - i - 1$ must be moved
			- Number of basic operations this requires is $\Theta (n-i)$
		- At extremes:
			- Inserting/deleting at front of Python list ($i = 0$) takes $\Theta (n)$ time
			- Inserting/deleting at the back of a Python list ($i = n - 1$) is a constant-time operation

## Summary: list mutating method running times

| Operation                                        | Running time ($n =$ `len(lst)`) |
| ------------------------------------------------ | ------------------------------- |
| List indexing (`lst[i]`)                         | $\Theta (1)$                    |
| List index assignment (`lst[i] = ...`)           | $\Theta (1)$                    |
| List insertion at end (`lst.append(...)`)        | $\Theta (1)$                    |
| List deletion at end (`lst.pop()`)               | $\Theta (1)$                    |
| List insertion at index $i$ (`lst.insert(i, ...)`) | $\Theta (n-i)$                  |
| List deletion at index $i$ (`lst.pop(i)`)             | $\Theta (n-i)$                  |
{ #9e90bc}


### When space runs out
- We make an assumption that there will always be free memory blocks at the end of the list for the list to expand into
	- Almost always true in practice

# Running-time analysis with list operations

### **Example.** Analyze running time of the following function:

```python
def squares(numbers: list[int]) -> list[int]:
	"""Return a list containing the squares of the 
	given numbers."""
	squares_so_far = []
	for number in numbers:
		squares_so_far.append(number ** 2)
	
	return squares_so_far
```

*Running time analysis.*
- Let $n$ be the length of the input list `numbers`
- Function body consists of three statements:
	- Assignment statement `squares_so_far = 0` counts as 1 step
	- For loop:
		- Takes $n$ iterations
		- Inside loop body, we call `squares_so_far.append(numbers ** 2)`, which tkaes *constant time* ($\Theta (1)$ steps)
		- Thus, for loop takes $n \cdot 1 = n$ steps total
	- Return statement counts as 1 step
- Total running time is the sum of these parts: $1 + n + 1 = n + 2$, which is $\Theta (n)$
<div class="right-align"> <span class="math display">\blacksquare</span> </div>


### **Example.** `list` method that results in a dramatic difference in running time

```python
def squares_reversed(numbers: list[int]) -> list[int]:
	"""Return a list containing ths quares of the given numbers, 
	in reverse order."""
	squares_so_far = []
	
	for number in numbers:
		# Now, insert number ** 2 at the START of squares_so_far
		list.insert(squares_so_far, 0, number ** 2)
	
	return squares_so_far
```

*Running time analysis.*
- Let $n$ be the length of the input list `numbers`
- Assignment statement `squares_so_far = 0` counts as 1 step
	- as its runnign time does not depend on the length of `numbers`
- For loop:
	- Takes $n$ iterations
	- Inside loop body, we call `list.insert(squares_so_far, 0, n ** 2)`
		- Inserting at the front of a Python list causes all of its current elements to be shifted over, taking time proportional to the size of the list
		- This call takes $\Theta (k)$ time, where $k$ is the current length of `squares_so_far`
			- We count a function call with $\Theta (k)$ time as taking $k$ steps, ignoring the “eventually” and “constant factors” part of the definition of Theta → we say loop body takes $k$ steps
	- To calculate total running time of the loop, we need to add the running times of every iteration:
		- `squares_so_far` starts as empty, then increases in length by `1` at each iteration
		- So, $k$ takes on the values `0, 1, 2, ..., n - 1`, and we calculate total running time of for loop using a summation:
		  $$\sum\limits_{k=0}^{n-1} k = \frac{{(n-1)n}}{2}$$
- Return statement counts as 1 step
	- Running time does not depend on the length of `numbers`
- The total running time is the sum of these three parts:
  $$1 + \frac{(n-1)n}{2} + 1 = \frac{{(n-1)n}}{2} + 2$$
  which is $\Theta (n^{2})$
<div class="right-align"> <span class="math display">\blacksquare</span> </div>

> [!note] Summary
> Single line of code change (from `list.append` to `list.insert` at index 0) causes running time to change dramatically from $\Theta (n)$ to $\Theta (n^{2})$.
> - Must always be conscious of which functions/operations we are using on data types

# Sets and dictionaries


<div class="transclusion internal-embed is-loaded"><div class="markdown-embed">



# Sets

- Set operations:
	- `x in my_set`
	- `set.add`
	- `set.remove`
- Run time of set operations:
	- $\Theta (1)$ — constant time
- How are sets implemented in Python?
	- Implemented using **hash tables**
	- Based on arrays
	- Figures out where to store something based on **hash function**


</div></div>



<div class="transclusion internal-embed is-loaded"><div class="markdown-embed">



# Dictionaries

- Dictionary operations:
	- key search (`k in my_dict`)
	- key lookup/assignment (`my_dict[k]` or `my_dict[k] = ...`) 
- Run time of dictionary operations:
	- $\Theta (1)$
	- Similar implementation to sets


</div></div>


# Data classes 

From Lecture 24,

<div class="transclusion internal-embed is-loaded"><div class="markdown-embed">



# Data classes

- Data class operations:
	- attribute lookup (`david.age`)
	- attribute assignment (`david.age = ...`)
- Run time of data class operations:
	- $\Theta (1)$
	- Similar implementation to dictionaries (and sets)


</div></div>


# Aggregation functions


<div class="transclusion internal-embed is-loaded"><div class="markdown-embed">



# Some built-in aggregation functions

- Run time of `sum`, `max`, `min`:
	- $\Theta (n)$, where $n$ is the size of the collection
- Run time of `len`:
	- $\Theta (1)$
	- A “hidden” size attribute stored by the Python interpreter for every collection object
- Run time of `any`/`all`:
	- Special; implemented with an *early return*
	- `any` can stop as soon as it encounters a `True`
		- Running time depends on the location of the first `True` value
	- `all` can stop as soon as it encounters a `False`
	- Run time can vary, depending on the *contents* of the collection



</div></div>




