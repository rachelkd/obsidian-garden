---
{"dg-publish":true,"permalink":"/900-archive/uof-t/y1/hps-120/key-terms-3/","created":"2023-12-01T11:37:19.483-08:00","updated":"2023-12-12T11:38:51.622-08:00"}
---

#HPS120 

---

# Week 10 - Meta-Analysis

See [[900 Archive/UofT/Y1/HPS120/01 Lecture Notes/10 Meta-Analysis\|10 Meta-Analysis]].

### P-hacking
- **What**
	- P-hacking is a technique in academic research where researchers selectively choose analyses that produce significant results rather than the best analysis plan. 
- **Where**
	- This term appeared in the lecture about meta-analysis.
- **Why**
	- P-hacking can lead to the publication of false positive results, which hinders scientific progress and can have a negative impact on future research in the field. It misuses data analysis to find patterns in data that can be presented as statistically significant when there is no real underlying effect.
	- Norman et. al found a suspiciously high number of studies just under the significant threshold 0.05. This suggests that p-hacking occurs somewhat often and bypasses the peer review process. This poses the question: is scientific literature poisoned by research that is not representative of the truth?
	- As science promises itself to be self-correcting, the answer is hopefully no. One particular study is not enough to be considered proof. Replication labs will expose the validity of research results. Additionally, researchers conduct meta-studies that look at a collection of individual studies that can reveal trends in the literature. Optimistically, false positives can be ruled out by opposing such trends.
### Case-Control Studies
- **What**
	- A case-control study is a type of observational study that compares two existing groups differing in outcome based on some supposed causal attribute. The group of individuals who have the outcome of interest (cases) is compared to a group of individuals who do not have the outcome of interest (controls). The researcher looks at factors to identify if some exposure is found more commonly in the cases than in the controls.
- **Where**
	- This term appeared in the lecture about meta-analysis.
- **Why**
	- There was a debate about the validity of case-control studies determining causal connections. Some argued that due to their retrospective nature, case-control studies can only establish a correlation between factors and outcomes but cannot establish causation.
	- However, Sir Austin Bradford Hill’s case-control study on smoking and lung cancer provides solid evidence that smoking does cause lung cancer; Hill provided a causal story based on scientific literature that explained the link between smoking and lung cancer. Case-control studies with the Hill strategy — a causal inference — are able to establish causation.
### Meta-Analysis
- **Where**
	- The term, meta-analysis, appeared in the lecture about meta-analysis.
- **What**
	- A meta-analysis is a statistical analysis that combines the results of multiple individual studies to derive a cumulative estimate closest to the unknown common truth based on the trends in the literature.
	- It is possible for scientific fraud and dishonest research to pervade scientific literature. A meta-analysis can help to reduce the impact of false positives by pooling the results of multiple studies and providing a more reliable estimate of the effect size. 
- **Why**
	- However, there is an argument that meta-studies are malleable. Meta-studies do not constrain researchers sufficiently to come up with just one conclusion: researchers make choices about which studies to include, how to measure the outcomes of such studies, and how to weigh various studies. There is no principled rule for these choices. These choices open the gate to bias. There have been cases of different meta-studies on similar topics with contradictory conclusions, and analysts who receive funding from the tobacco industry are more likely to conclude that passive smoking has no adverse health effects. If researchers have an agenda, they can conduct a meta-study that supports their hypothesis.
	- One potential solution to mitigate bias is to include a causal inference in meta-analyses. There should be some qualitative data from the literature in addition to the quantitative data in the meta-analysis.

# Week 11 - AI in Science

See [[900 Archive/UofT/Y1/HPS120/01 Lecture Notes/11 AI in Science\|11 AI in Science]].

### Deep Learning
- **Where**
- **What**
- **Why**
### Umbrella terms
- **What**
	- Umbrella terms refer to concepts that have overlapping but not perfectly clear definitions. It is difficult to come up with very crisp and clear definitions of umbrella terms.
	- For example, gold is a term with a clear definition: there are properties that allow scientists to classify something as gold. Not all concepts in science are like this.
- **Where**
	- This term appeared in the lecture about AI in science.
- **Why**
	- Umbrella terms make it difficult for artificial intelligence to achieve algorithmic fairness. A human has to feed data and instructions to neural networks. These AI systems optimize exactly and only for what we tell them to optimize it for.
	- Umbrella terms are ambiguous. This can cause problems when training AI models because the ambiguous data can lead models to find spurious correlations rather than accurate causal relationships.
	- If an individual claims to be associated with gang members because of a family member, neural networks might predict higher recidivism rates regardless if the individual is not gang-related.
	- This seems to suggest that artificial intelligence has problematic applications when data is ambiguous. Nevertheless, this does not mean that AI has no place in science. When goals are well-specified and the routes to those goals are well-understood, AI can be very helpful.
### Recidivism Prediction
- **Where**
- **What**
- **Why**

# Week 12 - Science Communications

See [[900 Archive/UofT/Y1/HPS120/01 Lecture Notes/12 Science Communications\|12 Science Communications]].
### Honest hype
- **Where**
	- The term, “honest hype,“ appeared in the lecture about science communications. It has become a part of the job of a scientist to communicate and promote their work. Communication of results to the broader public attracts interest, which increases funding and prestige. However, making something widely understood requires simplification. Consequently, simplification might distort the science presented.
- **What**
	- Honest hype is promoting your work that you genuinely believe is important without exaggerating claims beyond what is supported by evidence.
- **Why**
	- Weingart (2017) defines hype as the excessive promotion of something, which exaggerates its importance or benefits. Hype is often inevitable when communicating something that one thinks is important. It is vital to distinguish honest hype from dishonest hype, which involves making exaggerated or false claims toeing the line between scientific integrity and misconduct.
	- Perhaps hype is caught between conflicting scientific norms. Science has become an environment that seeks novelty and relevance. However, the scientific community also values modesty and careful attention to research. The solution to reducing hype lies in a re-evaluation of science’s values.

### Incentives for hype
- **What**
	- Communication has become apart of the job of scientists. As a result, hype is often inevitable when communicating discoveries that a scientist thinks are important. Incentives for hype can help explain why one might exaggerate something’s importance or benefits.
	- One incentive is that there is immense pressure on individuals, institutions, and whole disciplines to produce earth-shattering results. Scientific careers depend on delivering big results. Institutions want to give the impression that they are funding groundbreaking work, and hype engenders prestige.
	- The media might be incentivized to hype applied research as they want to gather interest, and people tend to be interested in things that concern them.
	- Furthermore, there might be national and political pressures to exaggerate findings. Making science open creates an environment that rewards popular applause.
- **Where**
	- This term appeared in the lecture about science communications.
- **Why**
	- Hype is problematic as it might cause people to make unhealthy choices based on misunderstanding or erode overall public trust in science. The incentives for hype suggest that hype is a systemic issue. Thus, there must be some systemic change. One potential solution is to give scientists credit for incremental or negative findings. This changes the community’s strive for novelty and relevance.
### Science communications
- **What**
	- Science communications involves presenting scientific discoveries and research to both expert and non-expert audiences.
- **Where**
	- This term appeared in the lecture about “science communications.”
- **Why**
	- Science communicators face a difficult set of tradeoffs.
		- If a discovery is only available to specialists, it cannot help inform other areas of science, public understanding, or policy. Arguably, science should have social applications. If software engineers cannot understand experts in health sciences, then this impacts people’s ways of living.
		- However, to make something widely understood, information has to be simplified, which tends to distort. Important details or limitations of the research might be lost as such.
	- Nevertheless, the structure of science has been shaped to include science communications as part of the job of a scientist. Communication implies that what someone is saying is important. This inevitably leads to hype, which is the excessive promotion and possible exaggeration of something. 
	- As consumers of science communications, it is important to question the presentation of findings before basing choices — especially concerning health — on exaggerated claims.
